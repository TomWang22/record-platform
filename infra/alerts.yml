groups:
  - name: edge-health
    rules:
      # NGINX exporter down
      - alert: NginxExporterDown
        expr: up{job="nginx"} == 0
        for: 2m
        labels: { severity: warning }
        annotations:
          summary: "NGINX exporter is down"
          description: "Prometheus cannot scrape nginx-exporter for 2m."

      # High rate of 429s at the edge (over last 5m)
      - alert: NginxTooMany429
        expr: |
          sum(rate(nginx_http_requests_total{status="429"}[5m]))
          /
          clamp_min(sum(rate(nginx_http_requests_total[5m])), 1)
          > 0.05
        for: 5m
        labels: { severity: warning }
        annotations:
          summary: "High proportion of 429 responses"
          description: "More than 5% of requests are 429 over 5m. Investigate limits/bursts."

      # 5xx spike from NGINX (usually upstream errors)
      - alert: Nginx5xxSpike
        expr: sum(rate(nginx_http_requests_total{status=~"5.."}[5m])) > 1
        for: 5m
        labels: { severity: critical }
        annotations:
          summary: "NGINX 5xx rate is elevated"
          description: "5xx > 1 req/s over 5m. Check upstream health and timeouts."

  - name: infra-scrapes
    rules:
      # Any job target down (generic)
      - alert: TargetDown
        expr: up == 0
        for: 3m
        labels: { severity: warning }
        annotations:
          summary: "Prometheus target down"
          description: "Job {{ $labels.job }} target {{ $labels.instance }} is down."

  - name: edge-slos
    rules:
      - alert: EdgeHigh5xx
        expr: sum(rate(haproxy_backend_http_responses_total{backend="be_api",code="5xx"}[5m]))
              /
              clamp_min(sum(rate(haproxy_backend_http_responses_total{backend="be_api"}[5m])), 1) > 0.01
        for: 5m
        labels: { severity: page }
        annotations:
          summary: "Edge 5xx > 1% (5m)"
          desc: "HAProxy backend be_api 5xx ratio is >1% for 5 minutes."

      - alert: EdgeWriteLatencyP95High
        expr: histogram_quantile(
                0.95,
                sum by (le) (
                  rate(http_server_request_duration_seconds_bucket{job=~"api-gateway|records-service",method=~"POST|PUT|DELETE"}[5m])
                )
              ) > 0.12
        for: 10m
        labels: { severity: ticket }
        annotations:
          summary: "Write p95 > 120ms (10m)"
          desc: "API write latency p95 above 120ms."