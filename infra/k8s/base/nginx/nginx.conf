worker_processes auto;
events { worker_connections 4096; }

http {
  resolver 10.96.0.10 valid=10s ipv6=off;

  # --- client IP from XFF (first hop) ---
  set_real_ip_from 172.16.0.0/12;
  real_ip_header    X-Forwarded-For;
  real_ip_recursive on;
  map $http_x_forwarded_for $client_ip {
    ~^(?<first>[^,]+) $first;
    default           $remote_addr;
  }

  # --- basics ---
  sendfile on; tcp_nopush on; tcp_nodelay on;
  keepalive_timeout 65;
  client_max_body_size 10m;

  # --- gzip ---
  gzip on;
  gzip_min_length 256;
  gzip_types text/plain text/css application/json application/javascript application/xml text/javascript;

  # --- logging ---
  log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                  '$status $body_bytes_sent "$http_referer" "$http_user_agent" '
                  'rt=$request_time urt=$upstream_response_time '
                  'uaddr=$upstream_addr ucache=$upstream_cache_status';
  access_log /var/log/nginx/access.log main;
  error_log  /var/log/nginx/error.log warn;

  # --- proxy defaults ---
  proxy_http_version 1.1;
  proxy_set_header Connection "";
  proxy_set_header Host              $host;
  proxy_set_header X-Real-IP         $remote_addr;
  proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
  proxy_set_header X-Forwarded-Proto $scheme;
  proxy_connect_timeout 5s;
  proxy_send_timeout    30s;
  proxy_read_timeout    30s;

  # --- micro-cache for hot GETs ---
  proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:100m max_size=500m inactive=60s use_temp_path=off;
  proxy_cache_background_update on;
  proxy_cache_revalidate        on;

  # --- rate limit zones (must exist before any limit_req) ---
  limit_req_zone $client_ip zone=api_reads:20m  rate=3000r/s;
  limit_req_zone $client_ip zone=api_writes:10m rate=600r/s;
  limit_req_status 429;
  limit_req_log_level warn;

  # --- helpers for API path + cache toggles ---
  map $request_uri $api_stripped { ~^/api(?<rest>/.*)$ $rest; default $request_uri; }
  map $api_stripped $cache_allow { default 0; ~^/records(/[^/?]+)?$ 1; }
  map $http_authorization $has_auth { default 1; "" 0; }
  map "$cache_allow:$has_auth" $nocache { "1:1" 0; default 1; }

  # --- upstreams via Kube DNS ---
  map "" $gateway { default http://haproxy.record-platform.svc.cluster.local:8081; }
  map "" $web     { default http://webapp:3001; }

  # --- method classification for dispatch ---
  map $request_method $method_kind { default write; GET read; HEAD read; OPTIONS read; }
  map $http_x_loadtest $no_write_limit { "1" 1; default 0; }
  map "$method_kind:$no_write_limit" $dispatch {
    "write:1" @writes_nolimit;
    "write:0" @writes_withlimit;
    default   @reads;
  }

  server {
    listen 8080;

    location = /healthz     { add_header Content-Type text/plain; return 200 "ok\n"; }
    location = /api/healthz { proxy_pass $gateway/healthz; proxy_cache off; }

    # Send /auth/* to HAProxy (keep /auth prefix so HAProxy ACL can match)
    location ^~ /auth/ {
      proxy_pass $gateway;
      proxy_cache off;
    }

    # Hot GET: /api/records (cached + read limiter)
    location = /api/records {
      limit_req zone=api_reads burst=3000;
      proxy_set_header Authorization $http_authorization;
      proxy_pass $gateway$api_stripped$is_args$args;

      proxy_cache               api_cache;
      proxy_cache_methods       GET HEAD;
      # vary by Authorization to avoid cross-user cache bleed
      proxy_cache_key           $scheme$proxy_host$api_stripped$is_args$args$http_authorization;
      proxy_cache_lock          on;
      proxy_cache_lock_timeout  5s;
      proxy_cache_use_stale     error timeout updating http_500 http_502 http_503 http_504;
      proxy_cache_valid         200 30s;

      proxy_no_cache            $nocache;
      proxy_cache_bypass        $nocache;

      add_header X-Cache-Status $upstream_cache_status always;
      proxy_next_upstream       error timeout http_500 http_502 http_503 http_504;
      proxy_next_upstream_tries 3;
    }

    # All other /api go to a named location based on method
    location ^~ /api/ { try_files /__no_such_file__ $dispatch; }

    location @reads {
      proxy_set_header Authorization $http_authorization;
      proxy_set_header X-Original-URI $request_uri;
      proxy_pass $gateway$api_stripped$is_args$args;

      proxy_cache               api_cache;
      proxy_cache_methods       GET HEAD;
      proxy_cache_key           $scheme$proxy_host$api_stripped$is_args$args$http_authorization;
      proxy_cache_lock          on;
      proxy_cache_lock_timeout  5s;
      proxy_cache_use_stale     error timeout updating http_500 http_502 http_503 http_504;
      proxy_cache_valid         200 30s;

      proxy_no_cache            $nocache;
      proxy_cache_bypass        $nocache;

      add_header X-Cache-Status $upstream_cache_status always;
      proxy_next_upstream       error timeout http_500 http_502 http_503 http_504;
      proxy_next_upstream_tries 3;
    }

    location @writes_withlimit {
      limit_req zone=api_writes burst=800;
      proxy_set_header Authorization $http_authorization;
      proxy_set_header X-Original-URI $request_uri;
      proxy_pass $gateway$api_stripped$is_args$args;
      proxy_cache off;
    }

    location @writes_nolimit {
      proxy_set_header Authorization $http_authorization;
      proxy_set_header X-Original-URI $request_uri;
      proxy_pass $gateway$api_stripped$is_args$args;
      proxy_cache off;
    }

    error_page 429 = @ratelimited;
    location @ratelimited {
      add_header Retry-After 1 always;
      add_header Content-Type application/json;
      return 429 '{"error":"rate_limited","retry_after":"1s"}';
    }

    location / { proxy_pass $web; }
    location = /nginx_status { stub_status; access_log off; }
  }
}
